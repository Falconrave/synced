#
# Panopticon configuration.  Values that are purely angle brackets must be filled in i.e. everything
# but panopticon.name and panopticon.keystore up to cell.home

#
# Logging server settings
cell.name = msoy-aggregator
# cell.undername = msoy_scheduler
panopticon.name = panopticon-scheduler

#
# Authorization details.
auth.realm = test
auth.username = whirled
auth.password = 2CE4BC8D148513A656DE576485D60ABD

# Location of the SSL certificate used by the server to encrypt communication with clients.
# panopticon.keystore = <panopticon.home>/dist/panopticon.keystore

# Password used to access the keystore. 
panopticon.keystorePassword = 0b64d5e664cfbd3ce634f0df3f493ba6d568e84d

#
# Filesystem configuration
# S3 credentials and other Hadoop config.
# If omitted, events will be logged to a scratch filesystem on the local hard drive.
panopticon.fs.default.name = s3ooo://panopticon-whirled-events
panopticon.fs.s3ooo.awsAccessKeyId = 0J78MSXNTCGJ1TZDBE82
panopticon.fs.s3ooo.awsSecretAccessKey = bCe7bj7vBRJFFM8G3vhF0U7+C+WjR1q0LlbVRTjw

# Filesystem configuration for saving report definitions.  This should ideally be the same AWS
# account, but a different bucket.  If not defined, reports will be stored locally.
definitions.fs.default.name = s3://panopticon-aggregator-defs
definitions.fs.s3.awsAccessKeyId = 0J78MSXNTCGJ1TZDBE82
definitions.fs.s3.awsSecretAccessKey = bCe7bj7vBRJFFM8G3vhF0U7+C+WjR1q0LlbVRTjw

#
# Task locations
# At least one of these must exist to run the reporter
tasks.dir = tasks
tasks.java = aggregator_classes
# tasks.module = <Python module name>

#
# Base directories
# cell.home = /export/cell/<cell.name>
# panopticon.home = /export/<panopticon.name>


# Host name and port for the logging server. Defaults to 0.0.0.0:2001
#
# panopticon.hostname = 0.0.0.0
# panopticon.port = 2001

#
# Reporter configuration
reporter.hostname = localhost
reporter.port = 80

# HTTPD access log directory.
# reporter.httpdLog = <cell.home>/log

# Directory for downloaded events. If it doesn't exist, it will be created at startup.
# reporter.downloadRoot = /tmp/<cell.name>-downloads

#
# Aggregator configuration

# Schedules allowed in aggregation tasks.
# aggregator.schedule.HOURLY=0 0 * * * ?
aggregator.schedule.DAILY=0 0 1 * * ?
aggregator.schedule.NIGHTLY=0 0 5 * * ?
# aggregator.schedule.WEEKLY=0 0 3 ? * SUN
# aggregator.schedule.MONTHLY=0 0 3 1 * ?

# Address of the hadoop cluster to use.  If not set, will run the Hadoop tasks in the aggregator's JVM.
#panopticon.mapred.job.tracker=10.252.187.148:50002
#panopticon.mapred.system.dir=/mnt/hadoop/mapred/system

# Location of the JAR file to upload to hadoop for aggregation tasks.
# If relative, made absolute in cell.home
panopticon.hadoop.jar = msoy-hadoop-mr.jar

# Spooling
#
# Should events be spooled to a local directory? Defaults to "true".
# panopticon.spooling = true
#
# Local spooling directory.
# panopticon.spoolpath = /tmp/<cell.name>-spool
